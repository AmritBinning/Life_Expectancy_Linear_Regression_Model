{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "\n",
        "This notebook will contain the functions used to perform the feature engineering for our model. While not all the feature enginnering was used directly with the model, we have chosen to include all of them as all the outputs of this feature engineering were used when testing with VIF and StepWise to determine which variables would be better for training the model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "W2qFw2Kh7DOB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# importing the relevent packages and scalar needed for feature engineering.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler, MaxAbsScaler, PowerTransformer, Normalizer, MinMaxScaler"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T08:39:32.232454400Z",
          "start_time": "2023-07-10T08:39:29.718462400Z"
        },
        "id": "qH_3XuF67DOD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-07-10T08:39:25.831598700Z",
          "start_time": "2023-07-10T08:39:25.820382200Z"
        },
        "id": "uVbJmAQl7DOE"
      },
      "outputs": [],
      "source": [
        "# This code is using the Robust Scaler to scaler the data within the chosen columns\n",
        "\n",
        "def robust_scaling(df):\n",
        "\n",
        "    # We used these variables to be scaled using this scaler as when looking at their histograms within the EDA phase of the project, it was found that each of these had big outliers,\n",
        "    #and we wanted to maintain the distribution's shape while decreasing the impact of the outliers.\n",
        "    possible_scalings =['adult_mortality', 'hepatitis_b', 'measles', 'bmi', 'under_five_deaths', 'polio',\n",
        "                        'diphtheria', 'gdp_per_capita', 'population_mln', 'thinness_ten_nineteen_years',\n",
        "                        'thinness_five_nine_years']\n",
        "\n",
        "    features = [feature for feature in possible_scalings if feature in list(df.columns)]\n",
        "\n",
        "    # At this stage we turned the datatypes of each feature into floats.\n",
        "    df_robbed = df[features]\n",
        "\n",
        "    df_robbed = df_robbed.astype(float)\n",
        "\n",
        "    rob = RobustScaler()\n",
        "\n",
        "    rob.fit(df_robbed)\n",
        "\n",
        "    df_scaled = pd.DataFrame(rob.transform(df_robbed),columns=[col + '_rob' for col in df_robbed.columns])\n",
        "    # It was important to change the scale of the df_scaled dataframe in order to make sure that we could join the dataframe's back together correctly.\n",
        "    df_scaled['index'] = df.index\n",
        "\n",
        "    df_scaled = df_scaled.join(df, on='index')\n",
        "    df_scaled.set_index('index', inplace=True)\n",
        "\n",
        "    return df_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# This code is using the Max-Abs Scaler to scaler the data within the chosen columns\n",
        "\n",
        "def max_abs(df):\n",
        "\n",
        "    max_abs = MaxAbsScaler()\n",
        "\n",
        "    # We determine that these variables would benefit the most from this scaler as their histograms were zero centred with a lot of sparcity.\n",
        "    maxabs_columns = df[['adult_mortality', 'incidents_hiv', 'gdp_per_capita', 'population_mln']].copy()\n",
        "\n",
        "    max_abs.fit(maxabs_columns)\n",
        "\n",
        "    df_scaled_ma = pd.DataFrame(max_abs.transform(maxabs_columns), columns=[col + '_ma' for col in maxabs_columns.columns])\n",
        "\n",
        "    # It was important to change the scale of the df_scaled df in order to make sure that we could join the df's back together correctly.\n",
        "    df_scaled_ma['index'] = df.index\n",
        "\n",
        "    df_scaled_ma = df_scaled_ma.join(df, on='index')\n",
        "    df_scaled_ma.set_index('index', inplace=True)\n",
        "\n",
        "    return df_scaled_ma"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T08:39:26.177764500Z",
          "start_time": "2023-07-10T08:39:25.835557600Z"
        },
        "id": "gVsYa3fk7DOE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# This code is using the PowerTransformer Scaler to scaler the data within the chosen columns\n",
        "\n",
        "def power_transform(df):\n",
        "\n",
        "    pt = PowerTransformer()\n",
        "\n",
        "    # We selected these variables for this scaling as we thought that they would benefit the most from it due to their histograms being 'Non-Normal'.\n",
        "    pt_columns = df[['infant_deaths', 'under_five_deaths', 'adult_mortality', 'alcohol_consumption', 'hepatitis_b', 'measles', 'polio', 'diphtheria', 'incidents_hiv', 'gdp_per_capita', 'population_mln', 'thinness_ten_nineteen_years', 'thinness_five_nine_years', 'economy_status_developed', 'economy_status_developing']].copy()\n",
        "    pt.fit(pt_columns)\n",
        "\n",
        "    df_scaled_pt = pd.DataFrame(pt.transform(pt_columns), columns=[col + '_pt' for col in pt_columns.columns])\n",
        "\n",
        "    # It was important to change the scale of the df_scaled df in order to make sure that we could join the df's back together correctly.\n",
        "    df_scaled_pt['index'] = df.index\n",
        "\n",
        "    df_scaled_pt = df_scaled_pt.join(df, on='index')\n",
        "    df_scaled_pt.set_index('index', inplace=True)\n",
        "\n",
        "    return df_scaled_pt"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T08:39:26.564611400Z",
          "start_time": "2023-07-10T08:39:26.460748900Z"
        },
        "id": "aJwZpcEI7DOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# This code is using the Normaliser Scaler to scaler the data within the chosen columns\n",
        "\n",
        "def normaliser(df):\n",
        "    normalizer = Normalizer()\n",
        "\n",
        "    norm_cols = df[['year', 'infant_deaths', 'under_five_deaths','adult_mortality', 'alcohol_consumption', 'hepatitis_b', 'measles','bmi', 'polio', 'diphtheria', 'incidents_hiv', 'gdp_per_capita',\n",
        "                    'population_mln', 'thinness_ten_nineteen_years','thinness_five_nine_years', 'schooling', 'economy_status_developed','economy_status_developing']].copy()\n",
        "\n",
        "    normalizer.fit(norm_cols)\n",
        "    df_norm_scale = pd.DataFrame(normalizer.transform(norm_cols), columns=[columns + '_normed' for columns in norm_cols.columns])\n",
        "\n",
        "    df_norm_scale['index'] = df.index\n",
        "\n",
        "    df_norm_scale = df_norm_scale.join(df, on='index')\n",
        "    df_norm_scale.set_index('index', inplace=True)\n",
        "\n",
        "    return df_norm_scale"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T08:39:26.751856Z",
          "start_time": "2023-07-10T08:39:26.566607900Z"
        },
        "id": "ICCDEy0h7DOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# This code is using the MinMax Scaler to scaler the data within the chosen columns\n",
        "\n",
        "def min_max(df):\n",
        "\n",
        "    mm_scaler = MinMaxScaler()\n",
        "\n",
        "    mm_cols = df[['year', 'infant_deaths', 'under_five_deaths','adult_mortality', 'alcohol_consumption', 'hepatitis_b', 'measles','bmi', 'polio', 'diphtheria', 'incidents_hiv', 'gdp_per_capita',\n",
        "                  'population_mln', 'thinness_ten_nineteen_years','thinness_five_nine_years', 'schooling', 'economy_status_developed','economy_status_developing']].copy()\n",
        "\n",
        "    mm_scaler.fit(mm_cols)\n",
        "\n",
        "    df_min_max = pd.DataFrame(mm_scaler.transform(mm_cols), columns=[columns + '_min_max' for columns in mm_cols.columns])\n",
        "\n",
        "    df_min_max['index'] = df.index\n",
        "\n",
        "    df_min_max = df_min_max.join(df, on='index')\n",
        "    df_min_max.set_index('index', inplace=True)\n",
        "\n",
        "    return df_min_max"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T08:39:26.897467900Z",
          "start_time": "2023-07-10T08:39:26.752854500Z"
        },
        "id": "-yfzsFFx7DOG"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}